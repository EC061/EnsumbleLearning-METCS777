{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import mean, stddev, min, max, last, count, countDistinct, col, lit, struct, avg\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, \\\n",
    "                                      LinearSVC, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from functools import reduce\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_VARS = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "TARGET_COLUMN = 'target'\n",
    "TRAIN_FILE = '../Data/train_small.csv'\n",
    "TEST_FILE = '../Data/test_small.csv'\n",
    "CAT_FEATURES = ['B_30_last', 'B_38_last', 'D_114_last', 'D_116_last', 'D_117_last',\n",
    "                'D_120_last', 'D_126_last', 'D_63_last', 'D_64_last','D_66_last', 'D_68_last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setAppName(\"Train and Save Models\") \\\n",
    "    .set(\"spark.executor.memory\", \"8g\") \\\n",
    "    .set(\"spark.driver.memory\", \"8g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "data_train = spark.read.csv(TRAIN_FILE, header=True, inferSchema=True)\n",
    "data_test = spark.read.csv(TEST_FILE, header=True, inferSchema=True)\n",
    "data_train = data_train.fillna(0)\n",
    "data_test = data_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer_spark(df, CAT_VARS, TARGET_COLUMN):\n",
    "    all_cols = [c for c in df.columns if c not in ['customer_ID', 'S_2']]\n",
    "    cont_vars = [c for c in all_cols if c not in CAT_VARS + [TARGET_COLUMN]]\n",
    "    cont_vars_agg_exprs = [expr for c in cont_vars for expr in (\n",
    "        mean(c).alias(c + '_mean'),\n",
    "        stddev(c).alias(c + '_std'),\n",
    "        min(c).alias(c + '_min'),\n",
    "        max(c).alias(c + '_max'),\n",
    "        last(c).alias(c + '_last')\n",
    "    )]\n",
    "    cont_vars_agg = df.groupBy(\"customer_ID\").agg(*cont_vars_agg_exprs)\n",
    "    cat_vars_agg_exprs = [expr for c in CAT_VARS for expr in (\n",
    "        count(c).alias(c + '_count'),\n",
    "        last(c).alias(c + '_last'),\n",
    "        countDistinct(c).alias(c + '_nunique')\n",
    "    )]\n",
    "    cat_vars_agg = df.groupBy(\"customer_ID\").agg(*cat_vars_agg_exprs)\n",
    "    df_agg = cont_vars_agg.join(cat_vars_agg, \"customer_ID\")\n",
    "    target_column_df = df.select(\"customer_ID\", TARGET_COLUMN)\n",
    "    df_agg = df_agg.join(target_column_df, \"customer_ID\")\n",
    "    return df_agg\n",
    "\n",
    "data_train = feature_engineer_spark(data_train, CAT_VARS, TARGET_COLUMN).drop('customer_ID')\n",
    "data_test = feature_engineer_spark(data_test, CAT_VARS, TARGET_COLUMN).drop('customer_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_indexed\", handleInvalid='keep')\n",
    "    for column in CAT_FEATURES\n",
    "]\n",
    "continuous_features = [c for c in data_train.columns if c not in CAT_FEATURES and c != TARGET_COLUMN and not c.endswith('_indexed')]\n",
    "data_train = data_train.fillna(0)\n",
    "data_test = data_test.fillna(0)\n",
    "assembler_cont = VectorAssembler(inputCols=continuous_features, outputCol=\"features_raw\")\n",
    "scaler = MinMaxScaler(inputCol=\"features_raw\", outputCol=\"scaled_features\", min=0.1, max=0.9)\n",
    "final_feature_columns = [col + \"_indexed\" for col in CAT_FEATURES] + [\"scaled_features\"]\n",
    "assembler_final = VectorAssembler(inputCols=final_feature_columns, outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=indexers + [assembler_cont, scaler, assembler_final])\n",
    "model = pipeline.fit(data_train)\n",
    "train_indexed = model.transform(data_train)\n",
    "test_indexed = model.transform(data_test)\n",
    "train_selected = train_indexed.select(\"features\", TARGET_COLUMN).cache()\n",
    "test_selected = test_indexed.select(\"features\", TARGET_COLUMN).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_size = len(train_selected.select(\"features\").first()[0])\n",
    "layers = [feature_vector_size, feature_vector_size // 2 + 1, feature_vector_size // 4 + 1, 2]\n",
    "models = {\n",
    "    \"GBTClassifier\": GBTClassifier(featuresCol='features', labelCol='target'),\n",
    "    \"LinearSVC\": LinearSVC(featuresCol='features', labelCol='target'),\n",
    "    \"LogisticRegression\": LogisticRegression(featuresCol='features', labelCol='target'),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(featuresCol='features', labelCol='target'),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(featuresCol='features', labelCol='target'),\n",
    "    \"MultilayerPerceptronClassifier\": MultilayerPerceptronClassifier(featuresCol='features', labelCol='target', layers=layers)\n",
    "}\n",
    "\n",
    "paramGrids = {\n",
    "    \"GBTClassifier\": ParamGridBuilder() \\\n",
    "        .addGrid(GBTClassifier.maxDepth, [2, 5, 10]) \\\n",
    "        .addGrid(GBTClassifier.maxBins, [10, 20, 40]) \\\n",
    "        .build(),\n",
    "        \n",
    "    \"LinearSVC\": ParamGridBuilder() \\\n",
    "        .addGrid(LinearSVC.maxIter, [10, 100, 1000]) \\\n",
    "        .addGrid(LinearSVC.regParam, [0.1, 0.01]) \\\n",
    "        .build(),\n",
    "        \n",
    "    \"LogisticRegression\": ParamGridBuilder() \\\n",
    "        .addGrid(LogisticRegression.maxIter, [10, 100, 1000]) \\\n",
    "        .addGrid(LogisticRegression.regParam, [0.1, 0.01]) \\\n",
    "        .addGrid(LogisticRegression.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "        .build(),\n",
    "        \n",
    "    \"DecisionTreeClassifier\": ParamGridBuilder() \\\n",
    "        .addGrid(DecisionTreeClassifier.maxDepth, [2, 5, 10]) \\\n",
    "        .addGrid(DecisionTreeClassifier.maxBins, [10, 20, 40]) \\\n",
    "        .build(),\n",
    "        \n",
    "    \"RandomForestClassifier\": ParamGridBuilder() \\\n",
    "        .addGrid(RandomForestClassifier.numTrees, [10, 50, 100]) \\\n",
    "        .addGrid(RandomForestClassifier.maxDepth, [2, 5, 10]) \\\n",
    "        .addGrid(RandomForestClassifier.maxBins, [10, 20, 40]) \\\n",
    "        .build(),\n",
    "        \n",
    "    \"MultilayerPerceptronClassifier\": ParamGridBuilder() \\\n",
    "        .addGrid(MultilayerPerceptronClassifier.maxIter, [100, 200, 300]) \\\n",
    "        .addGrid(MultilayerPerceptronClassifier.blockSize, [128, 256]) \\\n",
    "        .build()\n",
    "}\n",
    "\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"target\")\n",
    "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"target\")\n",
    "\n",
    "results_path = \"evaluation_results.txt\"\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model_path = os.path.join(\"models\", f\"{name}_model\")\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading model: {model_path}\")\n",
    "        model = PipelineModel.load(model_path)\n",
    "        print(f\"Loaded model: {name}\")\n",
    "    else:\n",
    "        pipeline = Pipeline(stages=[model])\n",
    "        paramGrid = paramGrids[name]\n",
    "        crossval = CrossValidator(estimator=pipeline,\n",
    "                                    estimatorParamMaps=paramGrid,\n",
    "                                    evaluator=multi_evaluator,\n",
    "                                    numFolds=3)\n",
    "        cvModel = crossval.fit(train_selected)\n",
    "        model = cvModel.bestModel\n",
    "        model.save(model_path)\n",
    "        print(f\"Trained and saved model: {name}\")\n",
    "    \n",
    "    predictions = model.transform(test_selected)\n",
    "    accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
    "    precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"precisionByLabel\"})\n",
    "    recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"recallByLabel\"})\n",
    "    f1 = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
    "    auc = binary_evaluator.evaluate(predictions, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "    best_params = model.stages[-1].extractParamMap()\n",
    "    param_str = \", \".join([f\"{p.name}: {best_params[p]}\" for p in best_params])\n",
    "    result_string = (f\"Model: {name}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, \"\n",
    "                        f\"F1 Score: {f1}, AUC: {auc}\\n\")\n",
    "    parameters_string = f\"Best Parameters: {param_str}\\n\"\n",
    "    results.append(Row(model=name, accuracy=accuracy, precision=precision, recall=recall, f1=f1, auc=auc))\n",
    "    results.append(Row(model=name, parameters=parameters_string))\n",
    "\n",
    "results_df = spark.createDataFrame(results)\n",
    "results_df.write.text(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"GBTClassifier\", \"LogisticRegression\", \"DecisionTreeClassifier\", \"RandomForestClassifier\", \"MultilayerPerceptronClassifier\"]\n",
    "models = {name: PipelineModel.load(os.path.join(\"models\", f\"{name}_model\")) for name in model_names}\n",
    "\n",
    "predictions = [model.transform(test_selected).withColumnRenamed('probability', f'probability_{name}') for name, model in models.items()]\n",
    "combined_predictions = reduce(lambda df1, df2: df1.join(df2.drop(\"prediction\"), \"id\"), predictions)\n",
    "\n",
    "num_models = len(models)\n",
    "average_probability = combined_predictions.select(avg(struct([col(f\"probability_{name}\") for name in model_names]))).alias(\"avg_probability\")\n",
    "\n",
    "final_prediction = average_probability.withColumn('final_prediction', (col('avg_probability') > lit(0.5)).cast(\"integer\"))\n",
    "\n",
    "accuracy = multi_evaluator.evaluate(final_prediction, {multi_evaluator.metricName: \"accuracy\"})\n",
    "precision = multi_evaluator.evaluate(final_prediction, {multi_evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = multi_evaluator.evaluate(final_prediction, {multi_evaluator.metricName: \"recallByLabel\"})\n",
    "f1 = multi_evaluator.evaluate(final_prediction, {multi_evaluator.metricName: \"f1\"})\n",
    "auc = binary_evaluator.evaluate(final_prediction, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "result_string = f\"Ensemble Model - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}, AUC: {auc}\"\n",
    "print(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean, stddev, min, max, last, count, countDistinct\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, \\\n",
    "                                      GBTClassificationModel, LinearSVC, MultilayerPerceptronClassifier, LinearSVCModel, \\\n",
    "                                      LogisticRegressionModel, DecisionTreeClassificationModel, RandomForestClassificationModel, \\\n",
    "                                      MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_VARS = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "TARGET_COLUMN = 'target'\n",
    "TRAIN_FILE = '../Data/train_small.csv'\n",
    "TEST_FILE = '../Data/test_small.csv'\n",
    "CAT_FEATURES = ['B_30_last', 'B_38_last', 'D_114_last', 'D_116_last', 'D_117_last',\n",
    "                'D_120_last', 'D_126_last', 'D_63_last', 'D_64_last','D_66_last', 'D_68_last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/21 10:06:18 WARN Utils: Your hostname, DESKTOP-D1SJQQ6 resolves to a loopback address: 127.0.1.1; using 172.27.228.206 instead (on interface eth0)\n",
      "24/04/21 10:06:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/edward/miniconda3/envs/pyspark_env/lib/python3.12/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "24/04/21 10:06:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setAppName(\"Train and Save Models\") \\\n",
    "    .set(\"spark.executor.memory\", \"8g\") \\\n",
    "    .set(\"spark.driver.memory\", \"8g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "data_train = spark.read.csv(TRAIN_FILE, header=True, inferSchema=True)\n",
    "data_test = spark.read.csv(TEST_FILE, header=True, inferSchema=True)\n",
    "data_train = data_train.fillna(0)\n",
    "data_test = data_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer_spark(df, CAT_VARS, TARGET_COLUMN):\n",
    "    all_cols = [c for c in df.columns if c not in ['customer_ID', 'S_2']]\n",
    "    cont_vars = [c for c in all_cols if c not in CAT_VARS + [TARGET_COLUMN]]\n",
    "    cont_vars_agg_exprs = [expr for c in cont_vars for expr in (\n",
    "        mean(c).alias(c + '_mean'),\n",
    "        stddev(c).alias(c + '_std'),\n",
    "        min(c).alias(c + '_min'),\n",
    "        max(c).alias(c + '_max'),\n",
    "        last(c).alias(c + '_last')\n",
    "    )]\n",
    "    cont_vars_agg = df.groupBy(\"customer_ID\").agg(*cont_vars_agg_exprs)\n",
    "    cat_vars_agg_exprs = [expr for c in CAT_VARS for expr in (\n",
    "        count(c).alias(c + '_count'),\n",
    "        last(c).alias(c + '_last'),\n",
    "        countDistinct(c).alias(c + '_nunique')\n",
    "    )]\n",
    "    cat_vars_agg = df.groupBy(\"customer_ID\").agg(*cat_vars_agg_exprs)\n",
    "    df_agg = cont_vars_agg.join(cat_vars_agg, \"customer_ID\")\n",
    "    target_column_df = df.select(\"customer_ID\", TARGET_COLUMN)\n",
    "    df_agg = df_agg.join(target_column_df, \"customer_ID\")\n",
    "    return df_agg\n",
    "\n",
    "data_train = feature_engineer_spark(data_train, CAT_VARS, TARGET_COLUMN).drop('customer_ID')\n",
    "data_test = feature_engineer_spark(data_test, CAT_VARS, TARGET_COLUMN).drop('customer_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_indexed\", handleInvalid='keep')\n",
    "    for column in CAT_FEATURES\n",
    "]\n",
    "continuous_features = [c for c in data_train.columns if c not in CAT_FEATURES and c != TARGET_COLUMN and not c.endswith('_indexed')]\n",
    "data_train = data_train.fillna(0)\n",
    "data_test = data_test.fillna(0)\n",
    "assembler_cont = VectorAssembler(inputCols=continuous_features, outputCol=\"features_raw\")\n",
    "scaler = MinMaxScaler(inputCol=\"features_raw\", outputCol=\"scaled_features\", min=0.1, max=0.9)\n",
    "final_feature_columns = [col + \"_indexed\" for col in CAT_FEATURES] + [\"scaled_features\"]\n",
    "assembler_final = VectorAssembler(inputCols=final_feature_columns, outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=indexers + [assembler_cont, scaler, assembler_final])\n",
    "model = pipeline.fit(data_train)\n",
    "train_indexed = model.transform(data_train)\n",
    "test_indexed = model.transform(data_test)\n",
    "train_selected = train_indexed.select(\"features\", TARGET_COLUMN).cache()\n",
    "test_selected = test_indexed.select(\"features\", TARGET_COLUMN).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: GBTClassifier\n",
      "Model: GBTClassifier, Accuracy: 0.8656849620705043, Precision: 0.9082503556187767, Recall: 0.9129036101513166, F1 Score: 0.8653391277632483, AUC: 0.9266113729537194\n",
      "\n",
      "Loaded model: LinearSVC\n",
      "Model: LinearSVC, Accuracy: 0.8638107987505578, Precision: 0.9027565982404692, Recall: 0.9169546050279995, F1 Score: 0.8627054450263494, AUC: 0.9263057306273149\n",
      "\n",
      "Loaded model: LogisticRegression\n",
      "Model: LogisticRegression, Accuracy: 0.8730923694779117, Precision: 0.9055264688772542, Recall: 0.9273203860359823, F1 Score: 0.8714828711430652, AUC: 0.9332636219405903\n",
      "\n",
      "Loaded model: DecisionTreeClassifier\n",
      "Model: DecisionTreeClassifier, Accuracy: 0.8497991967871485, Precision: 0.9099462365591398, Recall: 0.8872870249017037, F1 Score: 0.8515432375499287, AUC: 0.7680224528365523\n",
      "\n",
      "Loaded model: RandomForestClassifier\n",
      "Model: RandomForestClassifier, Accuracy: 0.8602409638554217, Precision: 0.8919508554369043, Recall: 0.9255331824139164, F1 Score: 0.8573720316154725, AUC: 0.9213273643500588\n",
      "\n",
      "Loaded model: MultilayerPerceptronClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultilayerPerceptronClassifier, Accuracy: 0.8686300758589915, Precision: 0.9074531967502649, Recall: 0.9182652210175146, F1 Score: 0.867829983203917, AUC: 0.9314231793106735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_vector_size = len(train_indexed.select(\"features\").first()[0])\n",
    "layers = [feature_vector_size, feature_vector_size // 2 + 1, feature_vector_size // 4 + 1, 2]\n",
    "models = {\n",
    "    \"GBTClassifier\": GBTClassifier(featuresCol='features', labelCol='target'),\n",
    "    \"LinearSVC\": LinearSVC(featuresCol='features', labelCol='target'),\n",
    "    \"LogisticRegression\": LogisticRegression(featuresCol='features', labelCol='target'),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(featuresCol='features', labelCol='target'),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(featuresCol='features', labelCol='target'),\n",
    "    \"MultilayerPerceptronClassifier\": MultilayerPerceptronClassifier(featuresCol='features', labelCol='target', layers=layers)\n",
    "}\n",
    "\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"target\")\n",
    "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"target\")\n",
    "\n",
    "results_path = \"evaluation_results.txt\"\n",
    "with open(results_path, \"w\") as file:\n",
    "    for name, model in models.items():\n",
    "        model_path = os.path.join(\"models\", f\"{name}_model\")\n",
    "        if os.path.exists(model_path):\n",
    "            if name == \"GBTClassifier\":\n",
    "                model = GBTClassificationModel.load(model_path)\n",
    "            elif name == \"LinearSVC\":\n",
    "                model = LinearSVCModel.load(model_path)\n",
    "            elif name == \"LogisticRegression\":\n",
    "                model = LogisticRegressionModel.load(model_path)\n",
    "            elif name == \"DecisionTreeClassifier\":\n",
    "                model = DecisionTreeClassificationModel.load(model_path)\n",
    "            elif name == \"RandomForestClassifier\":\n",
    "                model = RandomForestClassificationModel.load(model_path)\n",
    "            elif name == \"MultilayerPerceptronClassifier\":\n",
    "                model = MultilayerPerceptronClassificationModel.load(model_path)\n",
    "            print(f\"Loaded model: {name}\")\n",
    "        else:\n",
    "            model = model.fit(train_selected)\n",
    "            model.save(model_path)\n",
    "            print(f\"Trained and saved model: {name}\")\n",
    "        \n",
    "        predictions = model.transform(test_selected)\n",
    "        accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
    "        precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"precisionByLabel\"})\n",
    "        recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"recallByLabel\"})\n",
    "        f1 = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"f1\"})\n",
    "        auc = binary_evaluator.evaluate(predictions, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
    "\n",
    "        result_string = f\"Model: {name}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}, AUC: {auc}\\n\"\n",
    "        print(result_string)\n",
    "        file.write(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
